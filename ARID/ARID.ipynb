{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import img_to_gamma\n",
    "import pandas as pd\n",
    "\n",
    "def find_classes(dir):\n",
    "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "def make_dataset(root, source):\n",
    "    #root:'./datasets/hmdb51_frames'\n",
    "    #source:'./datasets/settings/hmdb51/train_rgb_split1.txt'\n",
    "    if not os.path.exists(source):\n",
    "        print(\"Setting file %s for hmdb51 dataset doesn't exist.\" % (source))\n",
    "        sys.exit()\n",
    "    else:\n",
    "        clips = []\n",
    "        with open(source) as split_f:\n",
    "            data = split_f.readlines()\n",
    "            for line in data:\n",
    "                line_info = line.split()\n",
    "                clip_path = os.path.join(root, line_info[0]) #视频名称\n",
    "                duration = int(line_info[1]) #视频帧长\n",
    "                target = int(line_info[2]) #视频类别\n",
    "                item = (clip_path, duration, target)\n",
    "                clips.append(item)\n",
    "    return clips #(视频名称,帧长,标签)\n",
    "\n",
    "\n",
    "def ReadSegmentRGB(path, offsets, new_height, new_width, new_length, is_color, name_pattern, duration):\n",
    "    if is_color:\n",
    "        cv_read_flag = cv2.IMREAD_COLOR         # > 0\n",
    "    else:\n",
    "        cv_read_flag = cv2.IMREAD_GRAYSCALE     # = 0\n",
    "    interpolation = cv2.INTER_LINEAR\n",
    "\n",
    "    sampled_list = []\n",
    "    for offset_id in range(len(offsets)):\n",
    "        offset = offsets[offset_id]\n",
    "        for length_id in range(1, new_length+1):\n",
    "            loaded_frame_index = length_id + offset\n",
    "            moded_loaded_frame_index = loaded_frame_index % (duration + 1)\n",
    "            if moded_loaded_frame_index == 0:\n",
    "                moded_loaded_frame_index = (duration + 1)\n",
    "            frame_name = name_pattern % (moded_loaded_frame_index)\n",
    "            frame_path = path + \"/\" + frame_name\n",
    "            cv_img_origin = cv2.imread(frame_path, cv_read_flag)\n",
    "\n",
    "            if cv_img_origin is None:\n",
    "               print(\"Could not load file %s\" % (frame_path))\n",
    "               sys.exit()\n",
    "               # TODO: error handling here\n",
    "            if new_width > 0 and new_height > 0:\n",
    "                # use OpenCV3, use OpenCV2.4.13 may have error\n",
    "                cv2.imwrite('old_img.jpg', cv_img_origin)\n",
    "                cv_img = cv2.resize(cv_img_origin, (new_width, new_height), interpolation)\n",
    "                cv2.imwrite('resized_image.jpg', cv_img)\n",
    "\n",
    "            else:\n",
    "                cv_img = cv_img_origin\n",
    "            cv_img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "            sampled_list.append(cv_img)\n",
    "\n",
    "\n",
    "    # clip_input = np.concatenate(sampled_list, axis=2)\n",
    "    return sampled_list\n",
    "    # cv2.imwrite('dark_image.jpg', clip_input)\n",
    "\n",
    "\n",
    "    return clip_input\n",
    "\n",
    "def ReadSegmentRGB_light(path, offsets, new_height, new_width, new_length, is_color, name_pattern, duration, gamma):\n",
    "    if is_color:\n",
    "        cv_read_flag = cv2.IMREAD_COLOR         # > 0\n",
    "    else:\n",
    "        cv_read_flag = cv2.IMREAD_GRAYSCALE     # = 0\n",
    "    interpolation = cv2.INTER_LINEAR\n",
    "\n",
    "    sampled_list = []\n",
    "    for offset_id in range(len(offsets)):\n",
    "        offset = offsets[offset_id]\n",
    "        for length_id in range(1, new_length+1):\n",
    "            loaded_frame_index = length_id + offset\n",
    "            moded_loaded_frame_index = loaded_frame_index % (duration + 1)\n",
    "            if moded_loaded_frame_index == 0:\n",
    "                moded_loaded_frame_index = (duration + 1)\n",
    "            frame_name = name_pattern % (moded_loaded_frame_index)\n",
    "            frame_path = path + \"/\" + frame_name\n",
    "            cv_img_origin = cv2.imread(frame_path, cv_read_flag)\n",
    "            #####\n",
    "            cv_img_origin = img_to_gamma.gamma_intensity_correction(cv_img_origin,gamma)\n",
    "            #####\n",
    "            if cv_img_origin is None:\n",
    "               print(\"Could not load file %s\" % (frame_path))\n",
    "               sys.exit()\n",
    "               # TODO: error handling here\n",
    "            if new_width > 0 and new_height > 0:\n",
    "                # use OpenCV3, use OpenCV2.4.13 may have error\n",
    "                cv_img = cv2.resize(cv_img_origin, (new_width, new_height), interpolation)\n",
    "            else:\n",
    "                cv_img = cv_img_origin\n",
    "            \n",
    "            cv_img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "            sampled_list.append(cv_img)\n",
    "    return sampled_list\n",
    "    \n",
    "    clip_input = np.concatenate(sampled_list, axis=2)\n",
    "    return clip_input\n",
    "\n",
    "# def ReadSegmentFlow(path, offsets, new_height, new_width, new_length, is_color, name_pattern,duration):\n",
    "#     if is_color:\n",
    "#         cv_read_flag = cv2.IMREAD_COLOR         # > 0\n",
    "#     else:\n",
    "#         cv_read_flag = cv2.IMREAD_GRAYSCALE     # = 0\n",
    "#     interpolation = cv2.INTER_LINEAR\n",
    "\n",
    "#     sampled_list = []\n",
    "#     for offset_id in range(len(offsets)):\n",
    "#         offset = offsets[offset_id]\n",
    "#         for length_id in range(1, new_length+1):\n",
    "#             loaded_frame_index = length_id + offset\n",
    "#             moded_loaded_frame_index = loaded_frame_index % (duration + 1)\n",
    "#             if moded_loaded_frame_index == 0:\n",
    "#                 moded_loaded_frame_index = (duration + 1)\n",
    "#             frame_name_x = name_pattern % (\"x\", moded_loaded_frame_index)\n",
    "#             frame_path_x = path + \"/\" + frame_name_x\n",
    "#             cv_img_origin_x = cv2.imread(frame_path_x, cv_read_flag)\n",
    "#             frame_name_y = name_pattern % (\"y\", moded_loaded_frame_index)\n",
    "#             frame_path_y = path + \"/\" + frame_name_y\n",
    "#             cv_img_origin_y = cv2.imread(frame_path_y, cv_read_flag)\n",
    "#             if cv_img_origin_x is None or cv_img_origin_y is None:\n",
    "#                print(\"Could not load file %s or %s\" % (frame_path_x, frame_path_y))\n",
    "#                sys.exit()\n",
    "#                # TODO: error handling here\n",
    "#             if new_width > 0 and new_height > 0:\n",
    "#                 cv_img_x = cv2.resize(cv_img_origin_x, (new_width, new_height), interpolation)\n",
    "#                 cv_img_y = cv2.resize(cv_img_origin_y, (new_width, new_height), interpolation)\n",
    "#             else:\n",
    "#                 cv_img_x = cv_img_origin_x\n",
    "#                 cv_img_y = cv_img_origin_y\n",
    "#             sampled_list.append(np.expand_dims(cv_img_x, 2))\n",
    "#             sampled_list.append(np.expand_dims(cv_img_y, 2))\n",
    "\n",
    "#     clip_input = np.concatenate(sampled_list, axis=2)\n",
    "#     return clip_input\n",
    "\n",
    "\n",
    "class ARID(data.Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 root,\n",
    "                 source,\n",
    "                 phase,\n",
    "                 modality,\n",
    "                 name_pattern=None,\n",
    "                 is_color=True,\n",
    "                 num_segments=1,\n",
    "                 new_length=1,\n",
    "                 new_width=0,\n",
    "                 new_height=0,\n",
    "                 transform=None,\n",
    "                 target_transform=None,\n",
    "                 video_transform=None,\n",
    "                 ensemble_training = False,\n",
    "                 gamma=None):\n",
    "\n",
    "        classes, class_to_idx = find_classes(root)\n",
    "        clips = make_dataset_from_csv(root, source)\n",
    "        self.gamma=gamma\n",
    "        #clips:(视频名称, 帧长, 标签)\n",
    "\n",
    "        if len(clips) == 0:\n",
    "            raise(RuntimeError(\"Found 0 video clips in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Check your data directory.\"))\n",
    "\n",
    "        self.root = root\n",
    "        self.source = source\n",
    "        self.phase = phase\n",
    "        self.modality = modality\n",
    "\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.clips = clips\n",
    "        self.ensemble_training = ensemble_training\n",
    "\n",
    "        if name_pattern:\n",
    "            self.name_pattern = name_pattern\n",
    "        else:\n",
    "            if self.modality == \"rgb\":\n",
    "                self.name_pattern = \"img_%05d.jpg\"\n",
    "            elif self.modality == \"flow\":\n",
    "                self.name_pattern = \"flow_%s_%05d\"\n",
    "\n",
    "        self.is_color = is_color\n",
    "        self.num_segments = num_segments\n",
    "        self.new_length = new_length\n",
    "        self.new_width = new_width\n",
    "        self.new_height = new_height\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.video_transform = video_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        path, duration, target = self.clips[index]\n",
    "        print(duration)\n",
    "        duration = duration - 1\n",
    "        average_duration = int(duration / self.num_segments)\n",
    "        average_part_length = int(np.floor((duration-self.new_length) / self.num_segments))\n",
    "\n",
    "        offsets = []\n",
    "        for seg_id in range(self.num_segments):\n",
    "            if self.phase == \"train\":\n",
    "                if average_duration >= self.new_length:\n",
    "                    offset = random.randint(0, average_duration - self.new_length)\n",
    "                    #offset=2,\n",
    "                    # No +1 because randint(a,b) return a random integer N such that a <= N <= b.\n",
    "                    offsets.append(offset + seg_id * average_duration)\n",
    "                elif duration >= self.new_length:\n",
    "                    offset = random.randint(0, average_part_length)\n",
    "                    offsets.append(seg_id*average_part_length + offset)\n",
    "                else:\n",
    "                    increase = random.randint(0, duration)\n",
    "                    offsets.append(0 + seg_id * increase)\n",
    "            elif self.phase == \"val\":\n",
    "                if average_duration >= self.new_length:\n",
    "                    offsets.append(int((average_duration - self.new_length + 1)/2 + seg_id * average_duration))\n",
    "                elif duration >= self.new_length:\n",
    "                    offsets.append(int((seg_id*average_part_length + (seg_id + 1) * average_part_length)/2))\n",
    "                else:\n",
    "                    increase = int(duration / self.num_segments)\n",
    "                    offsets.append(0 + seg_id * increase)\n",
    "            else:\n",
    "                print(\"Only phase train and val are supported.\")\n",
    "        \n",
    "\n",
    "\n",
    "        if self.modality == \"rgb\":\n",
    "            clip_input = ReadSegmentRGB(path,\n",
    "                                        offsets,\n",
    "                                        self.new_height,\n",
    "                                        self.new_width,\n",
    "                                        self.new_length,\n",
    "                                        self.is_color,\n",
    "                                        self.name_pattern,\n",
    "                                        duration\n",
    "                                        )\n",
    "            clip_input_light = ReadSegmentRGB_light(path,\n",
    "                                        offsets,\n",
    "                                        self.new_height,\n",
    "                                        self.new_width,\n",
    "                                        self.new_length,\n",
    "                                        self.is_color,\n",
    "                                        self.name_pattern,\n",
    "                                        duration,\n",
    "                                        gamma=self.gamma\n",
    "                                        )\n",
    "        else:\n",
    "            print(\"No such modality %s\" % (self.modality))\n",
    "\n",
    "        if self.transform is not None:\n",
    "            clip_input = self.transform(clip_input)\n",
    "            clip_input_light = self.transform(clip_input_light)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        if self.video_transform is not None:\n",
    "            clip_input,clip_input_light = self.video_transform(clip_input,clip_input_light)\n",
    "        return clip_input,clip_input_light,target\n",
    "                \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('./ARID_frames/Pick/Pick_12_1', 54, 2),\n",
       " ('./ARID_frames/Pick/Pick_12_10', 80, 2)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_dataset_from_csv(root, source):\n",
    "    #root:'./datasets/hmdb51_frames'\n",
    "    #source:'./datasets/settings/hmdb51/train_rgb_split1.txt'\n",
    "    if not os.path.exists(source):\n",
    "        print(\"Setting file %s for hmdb51 dataset doesn't exist.\" % (source))\n",
    "        sys.exit()\n",
    "    else:\n",
    "        clips = []\n",
    "        temp = pd.read_csv(source)\n",
    "        for i in range(temp.shape[0]):\n",
    "            clip_path = os.path.join(root, temp.iloc[i][\"Video\"])\n",
    "            duration = int(temp.iloc[i][\"Duration\"]) \n",
    "            target = int(temp.iloc[i][\"ClassID\"])\n",
    "            item = (clip_path, duration, target)\n",
    "            clips.append(item)\n",
    "\n",
    "    return clips\n",
    "make_dataset_from_csv(root, source) \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ARID(root, source ,phase=\"train\" , modality=\"rgb\" , gamma=1.8 , num_segments = 10 , new_length= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./ARID_frames/\"\n",
    "source = \"./test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 240, 320, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(temp.__getitem__(0)[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
